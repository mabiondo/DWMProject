{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Support Vector Regressor MODEL\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For imports\n",
    "from notebooks import utility\n",
    "import importlib\n",
    "\n",
    "# For optimization\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data import\n",
    "Let's import the data that was previously cleaned"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (2215639403.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  Input \u001B[1;32mIn [1]\u001B[1;36m\u001B[0m\n\u001B[1;33m    Let's import the data that was previously cleaned\u001B[0m\n\u001B[1;37m                                                     ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"../DWMProjectData/formodel/X_train.csv\")\n",
    "y_train = pd.read_csv(\"../DWMProjectData/formodel/y_train.csv\")\n",
    "X_valid = pd.read_csv(\"../DWMProjectData/formodel/X_valid.csv\")\n",
    "y_valid = pd.read_csv(\"../DWMProjectData/formodel/y_valid.csv\")\n",
    "X_test = pd.read_csv(\"../DWMProjectData/formodel/X_test.csv\")\n",
    "y_test = pd.read_csv(\"../DWMProjectData/formodel/y_test.csv\")\n",
    "# Transform all y in a 1-dimensional array - required to avoid warning in model building\n",
    "y_train = np.ravel(y_train)\n",
    "y_valid = np.ravel(y_valid)\n",
    "y_test = np.ravel(y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Scale data\n",
    "For SVR, data scaling bring to much better results, although it is not strictly required. The reasons for this can be found [here](https://www.baeldung.com/cs/svm-feature-scaling) and [here](https://scikit-learn.org/stable/modules/svm.html) (They refears to SVM but for regression the reason are the same)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from utility import scale\n",
    "importlib.reload(utility)\n",
    "X_train, X_valid, X_test = scale(X_train, X_valid, X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Score function\n",
    "\n",
    "I defined the score functions used for the regression. For a more clear approach I wrote the function `print_metrics` in the file `utility.py` In particular, I decided to write a function that prints the following values to compare models:\n",
    "- mean absolute error\n",
    "- mean squared error\n",
    "- $r^2$, where the best score is 1, good is above 0.7\n",
    "- explained variance score, where the best score is 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "<module 'notebooks.utility' from 'C:\\\\Users\\\\marco\\\\Documents\\\\UNI\\\\Y3\\\\DataWebMining\\\\project\\\\DWMProject\\\\notebooks\\\\utility.py'>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utility import print_metrics\n",
    "importlib.reload(utility)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model building"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV 1/5] END ..............C=0.1, kernel=linear;, score=0.001 total time=   6.5s\n",
      "[CV 2/5] END .............C=0.1, kernel=linear;, score=-0.001 total time=   5.6s\n",
      "[CV 3/5] END ..............C=0.1, kernel=linear;, score=0.002 total time=   5.5s\n",
      "[CV 4/5] END ..............C=0.1, kernel=linear;, score=0.000 total time=   5.0s\n",
      "[CV 5/5] END ..............C=0.1, kernel=linear;, score=0.002 total time=   5.3s\n",
      "[CV 1/5] END ...............C=0.1, kernel=poly;, score=-0.256 total time=   4.3s\n",
      "[CV 2/5] END ...............C=0.1, kernel=poly;, score=-0.324 total time=   5.3s\n",
      "[CV 3/5] END ...............C=0.1, kernel=poly;, score=-3.852 total time=   5.3s\n",
      "[CV 4/5] END ............C=0.1, kernel=poly;, score=-6900.686 total time=   4.2s\n",
      "[CV 5/5] END ................C=0.1, kernel=poly;, score=0.009 total time=   4.9s\n",
      "[CV 1/5] END .................C=0.1, kernel=rbf;, score=0.000 total time=   2.5s\n",
      "[CV 2/5] END .................C=0.1, kernel=rbf;, score=0.004 total time=   2.4s\n",
      "[CV 3/5] END ................C=0.1, kernel=rbf;, score=-0.337 total time=   2.6s\n",
      "[CV 4/5] END .................C=0.1, kernel=rbf;, score=0.004 total time=   2.5s\n",
      "[CV 5/5] END .................C=0.1, kernel=rbf;, score=0.008 total time=   2.5s\n",
      "[CV 1/5] END .........C=0.1, kernel=sigmoid;, score=-6356.395 total time=  28.5s\n",
      "[CV 2/5] END .........C=0.1, kernel=sigmoid;, score=-4107.327 total time=  29.6s\n",
      "[CV 3/5] END .........C=0.1, kernel=sigmoid;, score=-7324.559 total time=  30.4s\n",
      "[CV 4/5] END .........C=0.1, kernel=sigmoid;, score=-3791.692 total time=  25.5s\n",
      "[CV 5/5] END .........C=0.1, kernel=sigmoid;, score=-4847.323 total time=  25.7s\n",
      "[CV 1/5] END ................C=1, kernel=linear;, score=0.000 total time=  33.5s\n",
      "[CV 2/5] END ...............C=1, kernel=linear;, score=-0.001 total time=  24.6s\n",
      "[CV 3/5] END ................C=1, kernel=linear;, score=0.002 total time=  23.7s\n",
      "[CV 4/5] END ...............C=1, kernel=linear;, score=-0.000 total time=  23.0s\n",
      "[CV 5/5] END ................C=1, kernel=linear;, score=0.003 total time=  20.8s\n",
      "[CV 1/5] END ..............C=1, kernel=poly;, score=-1631.033 total time=  13.2s\n",
      "[CV 2/5] END .................C=1, kernel=poly;, score=-1.003 total time=  15.6s\n",
      "[CV 3/5] END .................C=1, kernel=poly;, score=-0.115 total time=  12.7s\n",
      "[CV 4/5] END .............C=1, kernel=poly;, score=-74441.972 total time=  21.1s\n",
      "[CV 5/5] END .................C=1, kernel=poly;, score=-0.014 total time=  19.9s\n",
      "[CV 1/5] END ...................C=1, kernel=rbf;, score=0.006 total time=   5.1s\n",
      "[CV 2/5] END ...................C=1, kernel=rbf;, score=0.003 total time=   4.9s\n",
      "[CV 3/5] END ..................C=1, kernel=rbf;, score=-0.003 total time=   4.5s\n",
      "[CV 4/5] END ..................C=1, kernel=rbf;, score=-0.003 total time=   5.0s\n",
      "[CV 5/5] END ...................C=1, kernel=rbf;, score=0.005 total time=   4.9s\n",
      "[CV 1/5] END .........C=1, kernel=sigmoid;, score=-496880.051 total time=  22.7s\n",
      "[CV 2/5] END .........C=1, kernel=sigmoid;, score=-384601.874 total time=  26.4s\n",
      "[CV 3/5] END .........C=1, kernel=sigmoid;, score=-746352.016 total time=  31.2s\n",
      "[CV 4/5] END .........C=1, kernel=sigmoid;, score=-385516.938 total time=  27.5s\n",
      "[CV 5/5] END .........C=1, kernel=sigmoid;, score=-405785.200 total time=  28.5s\n",
      "[CV 1/5] END ...............C=10, kernel=linear;, score=0.001 total time= 3.6min\n",
      "[CV 2/5] END ..............C=10, kernel=linear;, score=-0.001 total time= 2.6min\n",
      "[CV 3/5] END ...............C=10, kernel=linear;, score=0.001 total time= 2.8min\n",
      "[CV 4/5] END ...............C=10, kernel=linear;, score=0.000 total time= 2.9min\n",
      "[CV 5/5] END ...............C=10, kernel=linear;, score=0.003 total time= 2.6min\n",
      "[CV 1/5] END ...............C=10, kernel=poly;, score=-12.614 total time= 2.9min\n",
      "[CV 2/5] END ................C=10, kernel=poly;, score=-2.138 total time= 3.6min\n",
      "[CV 3/5] END ................C=10, kernel=poly;, score=-0.482 total time= 2.4min\n",
      "[CV 4/5] END ..........C=10, kernel=poly;, score=-2093699.095 total time= 2.8min\n",
      "[CV 5/5] END ................C=10, kernel=poly;, score=-0.124 total time= 2.9min\n",
      "[CV 1/5] END .................C=10, kernel=rbf;, score=-0.027 total time=  39.7s\n",
      "[CV 2/5] END ..................C=10, kernel=rbf;, score=0.007 total time=  40.8s\n",
      "[CV 3/5] END .................C=10, kernel=rbf;, score=-0.045 total time=  58.7s\n",
      "[CV 4/5] END .................C=10, kernel=rbf;, score=-0.027 total time=  56.2s\n",
      "[CV 5/5] END ..................C=10, kernel=rbf;, score=0.003 total time=  57.0s\n",
      "[CV 1/5] END ......C=10, kernel=sigmoid;, score=-52714379.222 total time=  24.5s\n",
      "[CV 2/5] END ......C=10, kernel=sigmoid;, score=-30699621.901 total time=  28.7s\n",
      "[CV 3/5] END ......C=10, kernel=sigmoid;, score=-74695359.743 total time=  30.3s\n",
      "[CV 4/5] END ......C=10, kernel=sigmoid;, score=-46345662.002 total time=  19.9s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "param_grid = {\n",
    "    \"kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "    \"C\": [0.1, 1, 10, 100]\n",
    "}\n",
    "model_base = SVR(verbose=True)\n",
    "\n",
    "# model_fitted = RandomizedSearchCV(model_base, param_grid, n_jobs=1)\n",
    "model_fitted = GridSearchCV(model_base, param_grid, n_jobs=1, verbose=4)\n",
    "model_fitted.fit(X_train, y_train)\n",
    "print(f\"Best params are {model_fitted.best_params_}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model re-building with best parameters + Metrics"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_final = SVR(inserire parametri)\n",
    "X_train_n = pd.concat(X_train, X_valid)\n",
    "y_train_n = pd.concat(y_train, y_valid)\n",
    "model_final.fit(X_train_n, y_train_n)\n",
    "\n",
    "print_metrics(y_test, model_final.predict(X_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}